{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# あり・なしクイズをword2vecによって獲得したベクトルから求めてみた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 楽天データセットから学習した単語ベクトルを使って2クラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "% pylab inline\n",
    "from gensim.models import word2vec\n",
    "import os,sys,glob\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Input,Dropout,Activation\n",
    "\n",
    "# 楽天データセットから学習済みのモデルの読み込み\n",
    "wv_model = word2vec.Word2Vec.load('/mnt/drobo/masaki/word2vec/data_spd_out.model')\n",
    "keys = wv_model.wv.vocab.keys()\n",
    "\n",
    "# あるなしクイズの問題と正解\n",
    "wl=['猫','犬','町','村','音','臭い','坂','階段','一','二']\n",
    "# ある-> 1,なし -> 0\n",
    "train_y = keras.utils.to_categorical([1,0,1,0,1,0,1,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "猫 [0. 1.] [-8.71037170e-02  4.84089777e-02 -1.21691704e-01 -1.56820938e-02\n",
      "  8.34430307e-02 -3.38677429e-02  8.67218897e-02 -9.61828008e-02\n",
      "  1.46967888e-01  9.23410282e-02  4.01876196e-02 -2.59390334e-03\n",
      "  2.13633224e-01  1.41475173e-02 -3.51268873e-02  5.18774763e-02\n",
      "  1.34248704e-01 -1.16806827e-01  2.24577114e-01 -1.76376596e-01\n",
      " -4.66109179e-02 -2.14273930e-02 -3.68749276e-02 -4.87893708e-02\n",
      " -1.32327780e-01  2.20732465e-01 -3.51719409e-01  2.84637660e-01\n",
      "  5.44378115e-03  1.99129149e-01 -2.09159479e-01 -1.27070054e-01\n",
      "  6.91367164e-02  8.65624323e-02  1.23450883e-01  1.38002098e-01\n",
      " -7.42373541e-02  1.95960313e-01  8.18893593e-03  1.33944318e-01\n",
      " -1.13563210e-01 -5.29759750e-02 -4.38672423e-01  1.69639409e-01\n",
      " -2.29028448e-01  3.49942409e-02  3.11168760e-01  2.20863402e-01\n",
      " -7.68544376e-02  4.38808985e-02  3.27155381e-01  3.29593301e-01\n",
      "  8.21715780e-03  3.43357563e-01  4.08534050e-01  2.84122109e-01\n",
      "  2.01645672e-01  9.73021463e-02  1.81971908e-01 -6.38293894e-03\n",
      " -1.71921805e-01 -8.04719999e-02  9.07176137e-02  2.46482536e-01\n",
      " -2.21273065e-01 -5.64709939e-02  4.56909500e-02 -1.73179314e-01\n",
      "  3.04065589e-02 -1.24518886e-01  3.19361478e-01 -3.77395786e-02\n",
      "  4.29059900e-02  4.14045565e-02 -2.71037549e-01 -1.46675602e-01\n",
      " -3.47829610e-02  6.96476921e-02 -1.25929028e-01  3.43544722e-01\n",
      " -1.15244808e-02  2.62979209e-01  2.86610126e-02 -2.73792565e-01\n",
      "  2.15681940e-02  8.60452056e-02 -4.01974499e-01  8.37438682e-04\n",
      " -1.09641097e-01 -6.51146658e-03 -2.16694530e-02 -9.01495367e-02\n",
      " -4.05729152e-02  1.81014445e-02  8.00628066e-02  1.20425493e-01\n",
      "  2.12077554e-02  6.45821169e-02  5.50679639e-02  5.61938621e-03\n",
      "  1.62384167e-01  3.38536054e-01  1.06465518e-01 -6.30335137e-03\n",
      "  6.90302700e-02  1.73358530e-01 -3.12871546e-01  2.17478156e-01\n",
      "  1.19599454e-01 -5.70414551e-02  2.71199085e-02  1.06081285e-01\n",
      " -1.39897883e-01  1.85834229e-01  9.87304673e-02  6.30087182e-02\n",
      "  1.64093703e-01 -7.98468366e-02  1.27252966e-01  1.28499940e-01\n",
      "  6.33062199e-02 -1.93371102e-01 -1.46486476e-01 -4.73885536e-02\n",
      " -1.00025441e-02 -5.87938242e-02 -7.97409043e-02  1.45114839e-01\n",
      "  4.07811999e-02 -7.38063678e-02 -5.09399697e-02 -6.50336295e-02\n",
      " -1.30675882e-01  7.73034021e-02 -1.89609498e-01  2.62714267e-01\n",
      "  8.02699998e-02  2.97321081e-01  7.69043937e-02 -1.30144600e-02\n",
      " -5.34276031e-02 -1.30056322e-01  2.01809719e-01 -2.38162473e-01\n",
      " -7.58175105e-02 -1.78347826e-01  4.69406731e-02  2.88090587e-01\n",
      "  7.27494829e-04 -1.06560886e-01 -1.03516497e-01  2.94327904e-02\n",
      "  7.56252930e-02  1.46081313e-01  4.03092280e-02 -1.96640287e-02\n",
      " -1.05851851e-01  1.68419197e-01  4.06692624e-02 -2.65876234e-01\n",
      "  3.10833007e-01 -9.95325297e-02  1.15112498e-01 -1.09963454e-02\n",
      " -1.76374212e-01 -1.76577464e-01 -2.21398070e-01  9.82823893e-02\n",
      " -1.71831846e-01  2.13854462e-01 -2.80307084e-01 -1.19974568e-01\n",
      " -2.27269996e-02 -2.16971889e-01 -7.46648386e-02  1.68902233e-01\n",
      " -2.97340490e-02  1.00186154e-01  2.30237216e-01 -5.53706363e-02\n",
      " -2.30631560e-01 -1.07797943e-02 -1.67213921e-02  7.03288764e-02\n",
      " -1.33823708e-01 -5.08367494e-02 -1.05018266e-01 -2.66603142e-01\n",
      " -3.31323594e-01 -2.65803630e-03 -4.25709523e-02 -3.69009125e-04\n",
      " -1.17788553e-01 -9.31170210e-02  4.66572270e-02 -4.25680801e-02\n",
      "  8.86127651e-02 -4.57950570e-02 -1.54661043e-02 -3.15741710e-02]\n",
      "犬 [1. 0.] [-0.1311166   0.01801282  0.07761031 -0.0868435   0.12862523  0.03037604\n",
      "  0.0814199  -0.09097978  0.1051806  -0.02017425  0.04211905  0.0404674\n",
      "  0.26584193  0.03707569  0.06281627  0.27547756  0.06507277 -0.23044567\n",
      "  0.3773977  -0.3962529   0.04888816  0.04638866 -0.03582798  0.03674258\n",
      " -0.18647552  0.2921259  -0.50830126  0.2753001   0.008433    0.17187612\n",
      " -0.3840036  -0.2272572   0.30203167  0.14753594  0.04528035  0.10077806\n",
      " -0.14877799  0.40765634  0.11481028 -0.02487681  0.04518494  0.08938223\n",
      " -0.58610934  0.17866588 -0.20353524 -0.05446967  0.3981562   0.18829072\n",
      " -0.11235195  0.11495567  0.31785125  0.08129273  0.10968629  0.17065133\n",
      "  0.40831366  0.12591107  0.23048666  0.06757499  0.20401517 -0.05651978\n",
      " -0.07354604  0.02511613  0.22263221  0.09233123  0.05320939 -0.15359937\n",
      " -0.08993012 -0.36683628  0.01414523 -0.06012637  0.40957293  0.32343134\n",
      "  0.1581516  -0.13712618 -0.3239603  -0.13174003 -0.14645173  0.13453516\n",
      "  0.16227204  0.21050812 -0.20878851  0.28377047  0.07509111 -0.22867645\n",
      " -0.0630179   0.26080775 -0.4006456   0.01507737 -0.03270079  0.01346712\n",
      "  0.01008484 -0.09439912 -0.18196763  0.06160442 -0.03504871  0.26398888\n",
      "  0.06146628 -0.00907072  0.02866088  0.14798248  0.16692814  0.63759166\n",
      " -0.03369414  0.10776927  0.0305164   0.3134793  -0.43415344  0.35415682\n",
      "  0.05474878 -0.2621178   0.06931332  0.31043574 -0.27912915  0.07513509\n",
      "  0.05908944  0.14315769  0.11299431  0.03686338  0.22083297  0.07960291\n",
      "  0.35615927 -0.26943475 -0.44477364  0.00071181  0.060125   -0.08023465\n",
      " -0.01204182  0.15509063 -0.00648486 -0.05822006 -0.13854724 -0.0951476\n",
      " -0.05031109  0.1978089  -0.44640848  0.3389876   0.0886784   0.3223632\n",
      "  0.27052483  0.01663929  0.08968656 -0.07314608  0.23573394 -0.3559872\n",
      " -0.08288533 -0.24722622  0.03511072  0.17175873  0.01404795 -0.08878744\n",
      "  0.04551783 -0.10542653  0.18847932  0.10126472  0.02762736 -0.0356685\n",
      "  0.04521355  0.04022006 -0.0774044  -0.4086268   0.23939987 -0.0775409\n",
      "  0.19325379 -0.09177416 -0.01957374 -0.22195217 -0.34116623  0.1427633\n",
      " -0.08283459  0.2725357  -0.41494593 -0.17220403 -0.11094665 -0.35463884\n",
      " -0.10087843  0.2826674   0.10018253 -0.07582673  0.22400893 -0.17153649\n",
      " -0.34715116  0.10504328  0.13447581  0.06261797  0.02081795 -0.19388312\n",
      " -0.0946843  -0.39927396 -0.4616231  -0.1712989  -0.05337062 -0.0295809\n",
      " -0.19496743 -0.03662869  0.1337581  -0.11857869  0.19221419  0.01604607\n",
      " -0.09730311 -0.03528417]\n",
      "町 [0. 1.] [-1.37848645e-01  3.18083405e-01 -1.20687939e-01  1.96252596e-02\n",
      "  1.75160524e-02 -5.02872765e-02 -2.29896843e-01  2.77510025e-02\n",
      "  4.02235359e-01  3.11911404e-01 -1.29312992e-01 -2.00509310e-01\n",
      " -1.35105893e-01 -7.26545677e-02 -3.31371486e-01  7.04991519e-02\n",
      "  2.27905840e-01  3.50702077e-01  7.01187402e-02  2.31135458e-01\n",
      "  6.54642582e-02 -5.66651039e-02  3.10822755e-01  3.00776452e-01\n",
      " -1.26055405e-01  3.19942422e-02 -3.25103730e-01  1.69980884e-01\n",
      "  1.37150839e-01 -2.91951060e-01  6.43495768e-02  2.60529637e-01\n",
      " -1.08630985e-01 -2.18391448e-01 -1.41193137e-01  3.74133617e-01\n",
      " -2.10639965e-02 -1.46772400e-01 -3.26208957e-02  9.15049613e-02\n",
      " -1.49458677e-01  3.84899735e-01 -1.94893107e-01  6.39352202e-02\n",
      " -5.14948606e-01 -1.27257615e-01  8.55076090e-02  2.17014536e-01\n",
      "  5.10723352e-01  7.02479407e-02  2.41144910e-01 -3.47103447e-01\n",
      "  5.36807477e-02  4.94133085e-02 -2.68668920e-01  5.79101965e-02\n",
      "  2.10588068e-01 -8.82820785e-02  1.62687480e-01  1.77636936e-01\n",
      " -5.76112568e-02 -1.67286307e-01 -1.73281450e-02  2.88949162e-01\n",
      "  1.29280239e-01  1.04249559e-01 -7.97834396e-02 -1.94766700e-01\n",
      " -5.77531047e-02  1.33816510e-01  2.07276568e-01 -2.69171178e-01\n",
      "  3.12071353e-01  2.71697968e-01  1.75122157e-01  4.18333970e-02\n",
      "  4.51522358e-02  4.77797091e-01 -1.21671304e-01  8.98637101e-02\n",
      " -1.52104452e-01 -2.51372904e-02 -3.03052068e-01  2.83392251e-01\n",
      "  1.52942836e-01  5.47305979e-02 -1.41813383e-01 -7.07996786e-01\n",
      " -5.18075190e-02  5.16642556e-02  9.68902037e-02 -9.58185717e-02\n",
      "  2.30387852e-01 -9.14148092e-02  1.93305574e-02  3.18992734e-01\n",
      "  5.24753742e-02 -9.85164568e-02  1.53933093e-01 -2.14969199e-02\n",
      "  3.34475277e-04 -2.08271042e-01 -2.37129807e-01  3.14397901e-01\n",
      "  2.94663701e-02  2.57652462e-01 -2.21589610e-01 -8.11368898e-02\n",
      "  1.61365092e-01  1.53678730e-02  1.13674484e-01  3.52523357e-01\n",
      "  6.31811917e-02 -1.31149992e-01  1.92437559e-01  2.04337910e-01\n",
      " -1.41360953e-01 -2.96955466e-01 -2.22337380e-01  9.11838561e-02\n",
      " -4.17673662e-02  1.02121294e-01 -2.39282072e-01  2.59162020e-03\n",
      "  8.08676332e-02 -2.83856541e-01 -5.61992824e-01 -2.86085457e-01\n",
      "  1.27461255e-01 -1.29717112e-01  1.32867053e-01  1.57686114e-01\n",
      " -4.87289019e-02 -4.97313030e-03  1.59640193e-01  1.89678818e-01\n",
      " -2.02267077e-02  6.03623509e-01 -1.58057436e-01 -7.60900229e-02\n",
      " -1.27837062e-01 -1.92749515e-01  7.14216903e-02 -3.69933724e-01\n",
      " -2.30066985e-01  1.70419231e-01  1.56646892e-02  1.17231533e-01\n",
      "  8.23222175e-02 -1.49831101e-01 -2.89533705e-01 -5.20472676e-02\n",
      "  9.57519040e-02 -1.33619979e-01 -1.91327967e-02  1.00822777e-01\n",
      " -2.09542796e-01  2.26256385e-01  1.38712436e-01 -1.33896574e-01\n",
      "  9.03417065e-04 -3.72657239e-01  2.07718372e-01  1.62522405e-01\n",
      "  1.13089464e-03  1.54774293e-01 -1.57646701e-01 -2.33154088e-01\n",
      " -1.24966435e-01  9.37210172e-02 -2.86209822e-01 -1.13231048e-01\n",
      " -1.07025653e-01  2.59078294e-01 -1.14335984e-01 -4.21987996e-02\n",
      " -2.49357089e-01 -6.03899658e-02  8.15310478e-02 -2.60421783e-01\n",
      " -1.56774729e-01 -3.26982737e-02  1.42688140e-01 -2.23971978e-02\n",
      "  2.30608415e-02  2.07810625e-01 -3.45366187e-02 -9.56206471e-02\n",
      " -1.07321888e-01 -8.74160603e-02  2.49193996e-01  5.00135608e-02\n",
      " -2.54344523e-01 -1.30272329e-01  6.95691630e-02  1.24330580e-01\n",
      " -4.83902469e-02  1.04874663e-01  3.20562065e-01  1.00548463e-02]\n",
      "村 [1. 0.] [ 0.03010198  0.3075568  -0.15525906  0.03946749  0.02749046 -0.07127327\n",
      " -0.11581921  0.08619422  0.2286674   0.15644202 -0.04916019 -0.1201312\n",
      "  0.0757582   0.01014449 -0.08729113 -0.01211689  0.20775677  0.25132897\n",
      " -0.04635006  0.06597734  0.0174749  -0.02169333  0.0978984   0.12691702\n",
      " -0.05721933 -0.00468278 -0.23499615  0.04392205  0.09929393 -0.09110539\n",
      "  0.07750936  0.09923352 -0.04706171  0.03099894 -0.00054617  0.16081972\n",
      " -0.02243062 -0.01564624 -0.06926076 -0.03237555 -0.0781848   0.10496813\n",
      " -0.11267055  0.04650455 -0.16114423 -0.06122662  0.03637691  0.14044477\n",
      "  0.04440707 -0.04604929  0.11528183  0.04052683  0.03214667  0.19217616\n",
      "  0.01283967  0.12720945  0.13265806  0.0065118   0.06577394  0.03431745\n",
      " -0.12897156 -0.05749098 -0.06275153  0.14313817 -0.08251371 -0.01064877\n",
      " -0.01128473 -0.05684127 -0.07633313 -0.03468982  0.0772702  -0.16122358\n",
      "  0.11696579  0.15613665  0.04277771 -0.03699804  0.05730836  0.13804491\n",
      " -0.08885977  0.1215652  -0.00169005 -0.01844037 -0.04111778  0.01964882\n",
      "  0.1100051  -0.00653247 -0.14096253 -0.18864651 -0.12678953  0.07195766\n",
      "  0.04139207  0.00385512  0.21416928  0.01312189  0.12569372  0.08910969\n",
      "  0.11084531 -0.0097689   0.05413016 -0.01600055  0.16713125  0.00067284\n",
      " -0.20015045  0.08595752  0.00946667  0.0936143  -0.0287282   0.05754287\n",
      "  0.1642583   0.02688512 -0.03834276  0.26436648 -0.00813718  0.05951762\n",
      "  0.10743626  0.02827697  0.13047835 -0.12891303  0.16138154 -0.01969964\n",
      "  0.03551519 -0.03433513 -0.15237267 -0.04591881  0.06812269 -0.1756989\n",
      " -0.25996643 -0.06694841 -0.02218948 -0.06558212 -0.09372663  0.0103495\n",
      " -0.15818103  0.01364216 -0.12311377  0.19243217  0.07384263  0.2633148\n",
      " -0.06764408 -0.08182296  0.08599842 -0.10918825  0.01587325 -0.16704838\n",
      " -0.13421856  0.00497308  0.02647888  0.17389971  0.07315472 -0.11764294\n",
      " -0.16482116  0.03733877 -0.03440636 -0.03915702  0.04096002  0.01854132\n",
      " -0.10476923  0.19282784 -0.00880448 -0.05599859  0.0898487  -0.08093508\n",
      " -0.00358542  0.12615235 -0.07545222 -0.01879895 -0.03872591 -0.07984129\n",
      " -0.14390874  0.07104799 -0.15925638 -0.09058473 -0.01332285  0.03359503\n",
      " -0.00699084  0.04366017 -0.08525476 -0.0013802   0.10928562 -0.09803196\n",
      " -0.02238138 -0.02359265 -0.08602747 -0.03617244 -0.08114805  0.08613486\n",
      "  0.00809744 -0.21282217 -0.13639009  0.09644958  0.164563    0.04892071\n",
      " -0.14815244 -0.09593261 -0.0498054   0.05620021  0.03977963  0.04299803\n",
      "  0.07235875 -0.03031325]\n",
      "音 [0. 1.] [-0.1345461   0.08178836  0.13298036  0.14599086  0.19524908  0.08031446\n",
      "  0.38419425 -0.04365037  0.19461562 -0.07310164 -0.24458693  0.10382745\n",
      "  0.06515694 -0.00382714  0.07932054 -0.14580025  0.15790819 -0.14154676\n",
      " -0.05270313 -0.31250703 -0.19654126  0.01381448 -0.19501232  0.17362191\n",
      " -0.08149067  0.24746828 -0.2476094   0.06586733  0.12057526 -0.29053655\n",
      " -0.03767814 -0.15646936  0.24109887  0.22191198  0.08831638  0.02520939\n",
      " -0.1663728   0.10824955 -0.08572012 -0.04151838  0.01099608  0.09248007\n",
      " -0.4167048   0.09838789  0.05223604 -0.03725486  0.08210124 -0.07211565\n",
      "  0.0995627   0.2960422  -0.08328869  0.19942605  0.15159322 -0.01699012\n",
      "  0.17968574 -0.02732424 -0.05792666 -0.41064852  0.24477321  0.3403462\n",
      " -0.14523202  0.10176297 -0.14682432  0.32569635 -0.26840836 -0.09484743\n",
      "  0.22460555  0.09718416  0.13244003 -0.1257964  -0.04106673  0.01123401\n",
      "  0.31442213  0.23264529 -0.36020306 -0.24177332 -0.18656866  0.14397466\n",
      " -0.12973636  0.2990579   0.06084339  0.3038745   0.3363045  -0.040696\n",
      "  0.02992293 -0.16477945 -0.5401583   0.31750706  0.11287347  0.14411348\n",
      "  0.11228392  0.07508632  0.04001889  0.04668291  0.19163096 -0.23123041\n",
      "  0.19425768  0.18383268 -0.15534206 -0.13149099 -0.04931766  0.39153135\n",
      " -0.18953572 -0.1549368  -0.12992099  0.21075629  0.06769895  0.33731154\n",
      " -0.14120495 -0.2546676  -0.19411574  0.27680764 -0.09915107  0.15392986\n",
      " -0.0288643  -0.10164671  0.2913493   0.14699142  0.03915635  0.00073711\n",
      "  0.15638974 -0.14972755 -0.22278382 -0.35886878  0.314007    0.07543577\n",
      "  0.14202878  0.00959827 -0.05477444 -0.10973419 -0.08302168 -0.31604978\n",
      "  0.0439025   0.187062   -0.26026613  0.01839319 -0.27695975  0.00936738\n",
      "  0.17321245 -0.26621136  0.05198858  0.03585161 -0.0392792  -0.3531523\n",
      "  0.08237761 -0.01610453 -0.12003119  0.00340695  0.19369344 -0.44469553\n",
      "  0.22510496 -0.08350934  0.01304221  0.00563976  0.13097355 -0.04448019\n",
      " -0.20450604 -0.11756095 -0.0894877  -0.18939714  0.16299926 -0.06143651\n",
      " -0.07625931  0.06825735 -0.21733068 -0.00527827 -0.14333947 -0.01114719\n",
      " -0.01799161  0.40708354 -0.06771073  0.07395933 -0.17609002 -0.31156215\n",
      "  0.11207398  0.01534698  0.06919704  0.16685186 -0.04603129 -0.1452471\n",
      " -0.11969126  0.23942743 -0.2453457  -0.24046372 -0.15159672  0.00752539\n",
      "  0.0838232  -0.20143862 -0.22790125  0.22758383 -0.37718835 -0.16312087\n",
      " -0.07395063  0.06266244  0.03501586 -0.12483531 -0.27496278 -0.03613715\n",
      " -0.46841404 -0.24991415]\n",
      "臭い [1. 0.] [ 1.72464326e-02  1.65498167e-01 -2.96603404e-02  1.56756602e-02\n",
      "  1.42785475e-01 -3.39665785e-02  1.03071686e-02  8.64654779e-02\n",
      "  1.83487058e-01  3.89809050e-02 -1.50526717e-01 -3.68626751e-02\n",
      "  1.00442715e-01 -1.91703364e-02  2.20000446e-02  2.31356099e-02\n",
      "  9.42434892e-02  9.53667313e-02  6.32689744e-02 -8.40730891e-02\n",
      " -4.63009477e-02  2.62581818e-02  9.27853398e-03  4.70352955e-02\n",
      " -2.69636679e-02  2.66036522e-02 -2.12222651e-01 -1.12856028e-03\n",
      "  3.33243273e-02 -1.15425922e-01  1.09936986e-02  5.22886999e-02\n",
      "  6.62231818e-02  1.19733833e-01  4.08932567e-02  6.31306544e-02\n",
      " -9.33179334e-02  5.68106305e-03 -3.75772826e-02 -3.38789225e-02\n",
      "  2.34108809e-02 -8.22965987e-03 -9.80402008e-02  9.25424621e-02\n",
      " -9.91611332e-02 -1.20492525e-01  9.69357416e-02  9.68765244e-02\n",
      " -9.18033347e-02  9.60264727e-03  2.30066143e-02  4.65124622e-02\n",
      "  1.24868147e-01  1.71939388e-01  6.71232045e-02  1.89106718e-01\n",
      "  5.44198044e-02 -4.51729372e-02  1.74800038e-01  7.23472536e-02\n",
      " -1.09957740e-01 -6.60896525e-02 -7.29474872e-02  1.82470307e-01\n",
      " -1.75095305e-01 -1.05162263e-01  7.61098117e-02 -8.70732591e-03\n",
      " -1.03693888e-01 -1.05971105e-01  1.27255827e-01 -9.28942636e-02\n",
      "  2.10698381e-01  1.32021040e-01 -9.83430147e-02 -1.10708075e-02\n",
      "  3.03996764e-02  9.56381112e-02 -6.23239540e-02  1.07571371e-01\n",
      "  1.32855505e-01  1.00506350e-01  4.47846428e-02  3.54921818e-02\n",
      "  8.53433684e-02 -2.67310608e-02 -2.02619538e-01  2.55409535e-02\n",
      " -3.79652865e-02  1.08588748e-01  2.42229849e-02  5.14746830e-02\n",
      "  1.33455217e-01  9.04105902e-02  5.00790961e-02 -9.92363039e-03\n",
      "  7.62632415e-02  1.91748012e-02  6.41292632e-02 -3.32452729e-02\n",
      "  9.60137472e-02  9.98522639e-02 -1.82518095e-01  1.44455377e-02\n",
      " -4.36907746e-02  5.86772710e-02  4.83271256e-02  1.60171673e-01\n",
      "  4.83253784e-02 -1.26563823e-02 -5.83088100e-02  1.42044619e-01\n",
      " -2.80607753e-02  1.08354971e-01  6.72428161e-02 -1.03904285e-01\n",
      "  1.12561330e-01 -3.65842097e-02  1.63573846e-01 -1.03216916e-01\n",
      "  1.03903987e-01 -8.43006521e-02 -1.22705989e-01 -9.31514204e-02\n",
      "  1.35038719e-01 -7.22025558e-02 -8.03130642e-02 -4.62244935e-02\n",
      " -9.80366692e-02 -4.21008728e-02 -9.28960517e-02 -5.25209904e-02\n",
      " -9.10259690e-03  1.03670456e-01 -2.43536845e-01  8.04169178e-02\n",
      " -1.76703930e-02  6.11332729e-02 -2.93682367e-02 -1.86172929e-02\n",
      "  9.09478888e-02 -7.00952783e-02 -1.27259619e-03 -1.26555756e-01\n",
      "  8.06335732e-03 -1.59485806e-02  2.57501025e-02  4.10329588e-02\n",
      "  1.02711342e-01 -1.36567697e-01 -4.47930135e-02  3.22734728e-03\n",
      " -6.22204132e-02 -2.66749226e-02  1.10754050e-01  2.80886181e-02\n",
      " -7.91080445e-02  8.83484185e-02 -4.79059406e-02 -8.82055238e-02\n",
      "  9.45577249e-02  2.20754445e-02 -7.54426513e-03 -2.05796100e-02\n",
      " -1.63080152e-02 -9.67278928e-02 -2.53087115e-02 -4.87723909e-02\n",
      " -1.59360379e-01  1.06286205e-01 -1.56558260e-01 -5.98206259e-02\n",
      " -1.11388199e-01 -8.43168795e-02  2.14969958e-04  3.25319618e-02\n",
      "  5.38768657e-02  5.66740669e-02  9.04322565e-02 -8.34833179e-03\n",
      " -5.59657812e-02  7.96314552e-02 -7.85043240e-02 -5.40942438e-02\n",
      " -1.65503412e-01  6.69166620e-04  2.51839533e-02 -2.43609786e-01\n",
      " -5.85533343e-02  1.06945440e-01  8.93589109e-02 -9.52141825e-03\n",
      " -1.43640593e-01 -9.82746929e-02 -9.24371630e-02 -2.50496976e-02\n",
      " -5.20309666e-03  8.30706283e-02 -4.08769026e-02 -3.51062901e-02]\n",
      "坂 [0. 1.] [ 0.00753767  0.37524405 -0.17405328  0.0828096   0.12591755 -0.10216201\n",
      " -0.07603995  0.11566149  0.27504814  0.15058562 -0.04780028 -0.07361734\n",
      "  0.14373368  0.08446012 -0.13179497 -0.01060927  0.13090514  0.22823006\n",
      "  0.08305647  0.03206958  0.02555228 -0.04358929 -0.00323892  0.04298803\n",
      " -0.08133122  0.08079316 -0.25040838 -0.01094626  0.03851034 -0.15879811\n",
      "  0.00860531  0.05113859  0.00992806 -0.03190155  0.13109939  0.13207768\n",
      " -0.05649586  0.02695501  0.04340542 -0.00715869 -0.07069659  0.09254681\n",
      " -0.13442667  0.0179667  -0.14246848 -0.00956408  0.09934934  0.13718945\n",
      "  0.06823711 -0.0617476   0.05173796  0.06125413  0.0678475   0.16362113\n",
      "  0.1119746   0.1623149   0.09960307  0.05909066  0.02378446  0.09805812\n",
      " -0.15607265 -0.08863436 -0.05157292  0.1630512  -0.18327922 -0.08464624\n",
      "  0.04540715 -0.06430703 -0.084828   -0.10186545  0.12015823 -0.22506015\n",
      "  0.16916586  0.21033677 -0.04715057 -0.06919868  0.07043675  0.03840042\n",
      " -0.06382463  0.17286195  0.07346592  0.06950233  0.03271449 -0.01802944\n",
      "  0.20121656  0.03312179 -0.18241867 -0.10368559 -0.09280856  0.04298625\n",
      "  0.0124269   0.06895611  0.21111156  0.05750171  0.0809666   0.00180337\n",
      "  0.09087361  0.01286734  0.06208792 -0.02814169  0.07598057  0.01395976\n",
      " -0.10501665 -0.02367339 -0.00342404  0.02450507  0.05599166  0.10090353\n",
      "  0.03699235  0.03545295 -0.03375235  0.0596121  -0.02055299  0.01334553\n",
      "  0.056555   -0.01540796  0.08346    -0.09256693  0.09966974  0.04558431\n",
      " -0.07953431 -0.07847816 -0.08100775 -0.04494025  0.02661633 -0.09576411\n",
      " -0.10830382 -0.01207035  0.00612211 -0.06206448 -0.1242329  -0.03007618\n",
      " -0.06158497  0.05939145 -0.03043545  0.18201596  0.07779833  0.13402735\n",
      " -0.04056299 -0.0634559   0.09652194 -0.09312288 -0.02349065 -0.15818954\n",
      " -0.1099127  -0.08687007 -0.01518355  0.12044101  0.09587785 -0.18420686\n",
      " -0.14374459 -0.05776155 -0.00515523  0.03375965  0.03798047  0.05927418\n",
      " -0.08687533  0.13900898  0.01358592 -0.06207519  0.1337442  -0.13391533\n",
      " -0.02799735  0.13644652 -0.09063758  0.04317632 -0.10393378 -0.04297799\n",
      " -0.18219854  0.16426493 -0.09966109 -0.14339516 -0.00859038  0.04701798\n",
      "  0.06043251 -0.02178203 -0.07637677  0.06701083  0.06747407 -0.04665041\n",
      " -0.10787003  0.04894089 -0.1208202  -0.05733864 -0.14582542  0.14962745\n",
      "  0.01410869 -0.13559434 -0.13677374  0.0774737   0.12269183 -0.00935447\n",
      " -0.12856467 -0.07045917 -0.12333089  0.07981471 -0.01306905  0.02092874\n",
      "  0.04469338 -0.01185421]\n",
      "階段 [1. 0.] [-0.06777173  0.14968476 -0.01038854  0.0942136   0.05966098 -0.09102595\n",
      " -0.0022051   0.02643455  0.16045332  0.21966632 -0.06291185 -0.01682683\n",
      "  0.01334969 -0.00785114 -0.12215656  0.00883735  0.09374376  0.1624586\n",
      "  0.09260723  0.04132885  0.00887213 -0.02602905  0.09624981  0.13368092\n",
      " -0.02225608  0.055928   -0.21999125  0.03959994  0.05678589 -0.14111753\n",
      "  0.00570499  0.10594558 -0.07184223 -0.05376879  0.02685187  0.11794965\n",
      " -0.07977422 -0.1517108  -0.00492682 -0.02598812 -0.07688314  0.1183649\n",
      " -0.14859404  0.08238368 -0.23435168 -0.08123248  0.11004555  0.14153941\n",
      "  0.17362155 -0.02927284  0.02995427 -0.01938981  0.06378049  0.07150082\n",
      "  0.01927626  0.1543264   0.12470799 -0.02016288  0.03225429  0.08161196\n",
      " -0.03506823 -0.09045227  0.02189451  0.10252618 -0.03948944 -0.0720188\n",
      "  0.06997306 -0.03595572 -0.08005199  0.02483841  0.1578027  -0.18782546\n",
      "  0.19056249  0.18516642  0.06315051  0.0006657   0.07995938  0.13988493\n",
      " -0.12700269  0.14436127  0.08631407  0.10745787 -0.00990755  0.08203144\n",
      "  0.15868236  0.02270088 -0.17835607 -0.180539   -0.01282362  0.08919311\n",
      "  0.00235382  0.00244367  0.12616247 -0.00585878  0.01337857  0.04690897\n",
      "  0.12416103 -0.01483439  0.12362269 -0.00181715 -0.00859629 -0.01095107\n",
      " -0.1775473   0.06891221 -0.07304876  0.03628411  0.05072306  0.14569499\n",
      " -0.02394286  0.00763101  0.00977687  0.11268065 -0.05154446  0.02556503\n",
      "  0.0777071   0.02979553  0.11689102 -0.22824202  0.12115635 -0.02497783\n",
      " -0.02987811 -0.03978468 -0.15023924 -0.03715887  0.11134593 -0.06864907\n",
      " -0.12841633 -0.08667547  0.02932313 -0.05474557 -0.08306226 -0.05969309\n",
      "  0.0318035   0.10282836 -0.03339671  0.17745337  0.03108979  0.21317941\n",
      " -0.11711186 -0.10373822  0.07184323 -0.14626569 -0.02930551 -0.13142952\n",
      " -0.10104801  0.03748931  0.03825779  0.0589662   0.09294517 -0.20486917\n",
      " -0.17158973 -0.05864165  0.02488759 -0.05517169  0.09111333  0.07211727\n",
      " -0.11302708  0.12591468  0.0033202  -0.03599633  0.05560166 -0.11515922\n",
      "  0.02896672  0.10473916 -0.06571718  0.00231441 -0.18017139 -0.0978796\n",
      " -0.08940755  0.11991214 -0.14834282 -0.07593866 -0.04157449  0.1109131\n",
      "  0.02318229 -0.01940108 -0.04616726  0.03254827  0.01650912 -0.05734922\n",
      " -0.10869234  0.08830547 -0.08277394 -0.11659104 -0.14155328  0.11932766\n",
      "  0.0840411  -0.16503954 -0.08527392  0.02556526  0.16815041 -0.03520613\n",
      " -0.16093704 -0.07283991 -0.10233089  0.10760257 -0.07397919  0.07255828\n",
      "  0.09302326  0.00605137]\n",
      "一 [0. 1.] [-0.25574496  2.499395    1.5992941   0.39897433  0.14937967 -0.7318605\n",
      " -0.62596583 -0.23396675 -0.5098363   0.8129471  -0.48405504 -0.52510804\n",
      " -1.7515718  -0.89594597 -0.7650467   0.91988754 -0.88321376  0.2599725\n",
      "  1.1795269   1.3877084   1.2517663   0.6478364   2.8086011  -0.16262068\n",
      "  0.80054855  0.7402195   1.6674396  -0.7167551  -0.4794778  -1.7903897\n",
      " -0.1749021   1.4262451   0.2076512  -0.45768297  0.0782081   0.87011296\n",
      " -1.7608014  -1.82052     0.7775999  -1.4773647  -1.1876293   1.3558892\n",
      "  1.2374201   0.8914602  -0.5165102  -0.5537832   0.09177455 -0.8505258\n",
      "  0.5850612  -0.0597317  -2.300237   -2.2256901   0.82711583 -2.2595072\n",
      " -0.6796742  -1.3096068  -1.3066821   0.27954316 -0.6543496   0.56733453\n",
      "  2.1432223  -1.2926086  -0.04946683 -0.16672963  1.2618645  -1.0820793\n",
      "  1.7492605  -0.32407585 -0.5109101   0.35220975  0.07676021 -0.35361633\n",
      "  0.13390802 -0.70260465  0.8311869   1.2842296   1.2198465  -0.99125296\n",
      " -0.57241666  0.43149337  1.3835804   0.8103563   0.33653897  2.982247\n",
      "  0.6855989   1.1755937   1.666913   -2.4903526   0.7511901   0.98499674\n",
      " -0.21737622  0.60693556 -0.9847515  -1.2140399  -1.2522565  -0.76206505\n",
      " -2.3408995  -0.9906704  -0.39904153  1.4774358  -1.6020594  -0.9950567\n",
      " -0.3738154   1.2982551  -1.8836217   0.49121884  1.5994512   0.5936862\n",
      " -1.9048393   0.68150955  1.4624374   0.6356032   1.0550878  -0.763907\n",
      "  0.19201997 -0.328363    0.05159147 -1.4587553   1.1648434  -1.4759254\n",
      " -0.02764173  1.5960332  -0.31759363  0.29276296  1.0668967   0.5746778\n",
      " -1.1063873  -1.9981095   0.7880997   1.4394839  -0.767382    0.7723442\n",
      "  1.3225373   1.5404361  -1.9395337  -0.5662818   0.23193485 -0.46415913\n",
      " -0.7207584  -0.6612093   1.5737358   0.8691372  -0.71850914  0.02561483\n",
      " -0.8837825   1.2744551   1.3381013  -1.8279146   1.9809006  -0.4090902\n",
      "  0.09404097 -0.52414656  0.16736664 -1.9250757   0.57400906  1.09268\n",
      "  0.07057122  1.133565    0.5053636   0.47146088 -1.6853715  -0.19454668\n",
      " -0.54972976  0.912627    1.3243941   0.7960716  -0.37359637 -0.8587283\n",
      "  1.358538   -0.12098347  1.2896687  -0.15603405 -1.7265725   1.6952885\n",
      "  1.038178    0.23956853  0.42939997  0.91141266 -0.18074149  1.297377\n",
      "  1.4465703   0.06482766  0.81145626 -1.6174794   0.53274065  1.4963146\n",
      "  1.5464652  -0.11995289  0.1285749  -1.6569737   1.7162211  -1.1622702\n",
      " -0.5561524   1.2779181   0.05536872  0.78413254 -0.8373783   0.5496672\n",
      "  1.7848759   1.1771977 ]\n",
      "二 [1. 0.] [-0.823418    1.1939353   0.39825878 -0.03506561 -0.34287193 -0.66495365\n",
      " -0.48183525 -0.4621694  -0.81969166  0.9213616  -0.35055685 -0.9038426\n",
      " -1.0145088  -0.39360306 -1.4140549   1.3158082  -0.87182015  1.5790408\n",
      "  1.2629602   2.05902     1.1909502   0.9574575   2.8766732   0.4341027\n",
      "  0.39980322  1.2374189   0.35503227  0.09418824 -0.09691387 -1.8023366\n",
      "  0.27659452  1.1111625   0.7356611  -0.39453846 -0.3443359   0.5176683\n",
      " -1.2860559  -1.0964694   0.43044147 -0.7987199  -0.17171915  1.7822984\n",
      "  1.3135283   0.74442774 -0.9943178  -1.3635311   0.35128984 -0.0767495\n",
      "  1.1390533   0.36369556 -1.0729924  -1.6387485   0.74257344 -1.7387606\n",
      " -1.2902442  -1.5756288  -1.4806533   0.28085694 -0.12111226  0.21219721\n",
      "  1.3729818  -1.4673247  -0.30063102  0.4172186   1.3019493  -1.2561506\n",
      "  1.5643836  -0.22103135 -0.4702763   0.79591405 -0.03955423 -0.5089805\n",
      " -0.18200685 -0.7434608   0.6934077   0.8596734   0.6855826  -0.5982255\n",
      " -0.48162246  0.5595661   0.9550806   0.29017124  0.7078729   3.0060213\n",
      "  0.42541647  1.1631298   1.3369296  -3.4615963   0.7456381   0.9123739\n",
      " -0.08764968  0.57755    -0.92163056 -1.3408424  -1.1899875  -0.35410452\n",
      " -2.022004   -0.90965056 -0.05509239  1.2661102  -1.0463713  -1.0978172\n",
      " -0.10663106  1.4434034  -1.6000798   0.737766    0.7604104   0.33063692\n",
      " -1.236552    0.1720813   1.3727973   0.6717682   1.6142058  -1.1416566\n",
      "  0.90532357 -0.3181029  -0.3379864  -1.2247391   0.3881595  -1.2846007\n",
      " -0.00981891  1.0608755   0.4593212   0.49911538  0.48613587  0.60160685\n",
      " -1.2905732  -1.6003737   0.8107216   1.5486422  -0.9663416   0.648506\n",
      "  0.6040868   0.9489704  -1.2829442  -0.76936674  0.3613484   0.23945524\n",
      " -0.25580165 -0.4466579   0.4773079   0.5067453  -0.17860928 -0.2964551\n",
      " -1.1142505   1.2616751   1.2610936  -0.7694276   1.3489385  -0.34743953\n",
      " -0.61214453  0.2426527   0.09315874 -1.5323384   0.12706222  1.1169978\n",
      " -0.1491412   0.80125415  0.37948817  0.6810751  -1.7307732  -0.6828772\n",
      " -0.67751     0.76276785  1.4557109   1.1716577   0.27570266 -0.9642899\n",
      "  0.95826614 -0.23147266  0.69356763 -0.52291495 -1.5930051   1.2638131\n",
      "  0.58099574 -0.49087712  0.11659978  0.6789485   0.45552957  0.5210046\n",
      "  1.9821907   0.17633452  0.99172074 -1.298165    0.83013594  0.88545334\n",
      "  0.8149693   0.34786698  0.5353311  -1.3127255   1.1681548  -0.00912992\n",
      " -0.19412586  1.1605216   0.6586021   0.6872824  -0.57179147  0.34094688\n",
      "  2.0882185   0.9250617 ]\n"
     ]
    }
   ],
   "source": [
    "# 学習データを作成\n",
    "# model学習時に、単語-品詞として学習していたので、品詞を補っている\n",
    "\n",
    "train = []\n",
    "\n",
    "for w,l in zip(wl,train_y):\n",
    "    try:\n",
    "        vec = wv_model.wv[w+'-名詞']\n",
    "        train.append((vec))\n",
    "    except KeyError:\n",
    "        vec = wv_model.wv[w+'-形容詞']\n",
    "        train.append((vec))\n",
    "    print(w,l,vec)\n",
    "train_x = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 30,402\n",
      "Trainable params: 30,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.9524 - acc: 0.5000\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7193 - acc: 0.5000\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6863 - acc: 0.5000\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 382us/step - loss: 0.6784 - acc: 0.5000\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 377us/step - loss: 0.6732 - acc: 0.7000\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 545us/step - loss: 0.6686 - acc: 0.7000\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6643 - acc: 0.8000\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6601 - acc: 0.7000\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6560 - acc: 0.7000\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6518 - acc: 0.6000\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6476 - acc: 0.6000\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6432 - acc: 0.6000\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6389 - acc: 0.6000\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6343 - acc: 0.6000\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6297 - acc: 0.6000\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6249 - acc: 0.6000\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.6201 - acc: 0.6000\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 231us/step - loss: 0.6150 - acc: 0.6000\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.6098 - acc: 0.6000\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.6046 - acc: 0.6000\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.5991 - acc: 0.6000\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.5936 - acc: 0.6000\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 922us/step - loss: 0.5880 - acc: 0.6000\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5823 - acc: 0.6000\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5765 - acc: 0.6000\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 268us/step - loss: 0.5706 - acc: 0.6000\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 268us/step - loss: 0.5646 - acc: 0.6000\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 267us/step - loss: 0.5585 - acc: 0.6000\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5523 - acc: 0.8000\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 401us/step - loss: 0.5461 - acc: 0.8000\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5398 - acc: 0.8000\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 393us/step - loss: 0.5335 - acc: 0.8000\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5271 - acc: 0.8000\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 409us/step - loss: 0.5206 - acc: 0.8000\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 387us/step - loss: 0.5141 - acc: 0.8000\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 935us/step - loss: 0.5078 - acc: 0.8000\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5030 - acc: 0.7000\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5042 - acc: 0.7000\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5058 - acc: 0.7000\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 287us/step - loss: 0.4957 - acc: 0.7000\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4854 - acc: 0.7000\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4777 - acc: 0.8000\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4717 - acc: 0.8000\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4663 - acc: 0.8000\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 717us/step - loss: 0.4609 - acc: 0.8000\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.4556 - acc: 0.8000\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 529us/step - loss: 0.4501 - acc: 0.8000\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 644us/step - loss: 0.4445 - acc: 0.8000\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4388 - acc: 0.8000\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4330 - acc: 0.8000\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4272 - acc: 0.9000\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4217 - acc: 0.8000\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4165 - acc: 0.9000\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4120 - acc: 0.9000\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4079 - acc: 0.9000\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4034 - acc: 0.8000\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 399us/step - loss: 0.3975 - acc: 0.9000\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 632us/step - loss: 0.3906 - acc: 0.9000\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 420us/step - loss: 0.3839 - acc: 0.9000\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3774 - acc: 0.9000\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3712 - acc: 0.9000\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3652 - acc: 1.0000\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 462us/step - loss: 0.3593 - acc: 0.9000\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3535 - acc: 1.0000\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 298us/step - loss: 0.3476 - acc: 0.9000\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 538us/step - loss: 0.3418 - acc: 1.0000\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 336us/step - loss: 0.3361 - acc: 0.9000\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 290us/step - loss: 0.3306 - acc: 1.0000\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3253 - acc: 0.9000\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3200 - acc: 1.0000\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3147 - acc: 0.9000\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3091 - acc: 1.0000\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3033 - acc: 0.9000\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.2973 - acc: 1.0000\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 529us/step - loss: 0.2914 - acc: 0.9000\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2855 - acc: 1.0000\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 927us/step - loss: 0.2798 - acc: 0.9000\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 545us/step - loss: 0.2741 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2685 - acc: 1.0000\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2631 - acc: 1.0000\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2576 - acc: 1.0000\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2523 - acc: 1.0000\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2471 - acc: 1.0000\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 1.0000\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2369 - acc: 1.0000\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2319 - acc: 1.0000\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2269 - acc: 1.0000\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 1.0000\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2170 - acc: 1.0000\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2120 - acc: 1.0000\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 387us/step - loss: 0.2070 - acc: 1.0000\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2021 - acc: 1.0000\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1972 - acc: 1.0000\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1925 - acc: 1.0000\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 234us/step - loss: 0.1878 - acc: 1.0000\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1832 - acc: 1.0000\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1787 - acc: 1.0000\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1743 - acc: 1.0000\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1699 - acc: 1.0000\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 470us/step - loss: 0.1657 - acc: 1.0000\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1615 - acc: 1.0000\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 718us/step - loss: 0.1574 - acc: 1.0000\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1533 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1493 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1453 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 596us/step - loss: 0.1414 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1376 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1338 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 697us/step - loss: 0.1301 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 249us/step - loss: 0.1264 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 268us/step - loss: 0.1228 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.1193 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 259us/step - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1028 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 882us/step - loss: 0.0997 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0967 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 418us/step - loss: 0.0937 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0908 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 437us/step - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 402us/step - loss: 0.0853 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0826 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 285us/step - loss: 0.0773 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 304us/step - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 293us/step - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 269us/step - loss: 0.0699 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 890us/step - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 378us/step - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 384us/step - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 382us/step - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 458us/step - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 628us/step - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 561us/step - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 645us/step - loss: 0.0528 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 580us/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 407us/step - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 420us/step - loss: 0.0457 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 536us/step - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 808us/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 821us/step - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 867us/step - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 515us/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 597us/step - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 888us/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 851us/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 741us/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 691us/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 378us/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 368us/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 781us/step - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 886us/step - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 748us/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0189 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 953us/step - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 895us/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 587us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 394us/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 680us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 442us/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 538us/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 427us/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 351us/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 370us/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 374us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 356us/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 388us/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 870us/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 433us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 938us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 477us/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 787us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 648us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 578us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 624us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 420us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 405us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 273us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 317us/step - loss: 0.0034 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# model構築と学習\n",
    "model = Sequential()\n",
    "model.add(Dense(100,input_dim = 200,activation='sigmoid'))\n",
    "model.add(Dense(100,activation='sigmoid'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.summary()\n",
    "train_history=model.fit(train_x,train_y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff02e734588>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線\n",
    "xlabel('epochs')\n",
    "ylabel('loss and accuracy')\n",
    "plot(train_history.history['loss'],label='train loss') \n",
    "plot(train_history.history['acc'],label='train accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8171088  0.18289125]]\n"
     ]
    }
   ],
   "source": [
    "# では本題、過去は、どちらに分類されるか\n",
    "\n",
    "test_x = wv_model.wv['過去-名詞']\n",
    "#print(test_x)\n",
    "\n",
    "result=model.predict(np.array([test_x]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果 なし:約92%, あり:約8% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結論:「過去」は「なし」に分類されるらしい"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
